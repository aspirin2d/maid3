import { cosineDistance, desc, eq, gt, and, sql } from "drizzle-orm";
import type { z } from "zod";
import { db } from "./db/index.js";
import { memory } from "./db/schema.js";
import { getPendingUserMessages, markMessagesAsExtracted } from "./message.js";
import { Embeddding, StructureResponse } from "./openai.js";
import {
  FactRetrievalSchema,
  getFactRetrievalMessages,
  getUpdateMemoryMessages,
  MemoryUpdateSchema,
} from "./prompts/memory.js";

type MemoryExtractionStats = {
  factsExtracted: number;
  memoriesAdded: number;
  memoriesUpdated: number;
  messagesExtracted: number;
};

type ConversationMessage = Awaited<
  ReturnType<typeof getPendingUserMessages>
>[number];

type RetrievedFact = z.infer<typeof FactRetrievalSchema>["facts"][number];

type ExistingMemory = {
  unifiedId: string;
  originalId: number;
  text: string;
};

type FactMetadata = Pick<
  RetrievedFact,
  "category" | "importance" | "confidence"
>;

type PreparedDecision =
  | {
      kind: "ADD";
      text: string;
      metadata: FactMetadata;
      embeddingKey: string;
    }
  | {
      kind: "UPDATE";
      memoryIndex: number;
      text: string;
      embeddingKey: string;
    };

type DecisionPlan = {
  decisions: PreparedDecision[];
  embeddingByText: Map<string, number[]>;
};

type MemoryUpdateDecision = z.infer<
  typeof MemoryUpdateSchema
>["memory"][number];

const EMPTY_STATS: MemoryExtractionStats = {
  factsExtracted: 0,
  memoriesAdded: 0,
  memoriesUpdated: 0,
  messagesExtracted: 0,
};

const SIMILAR_MEMORY_TOP_K = 3;
const MIN_MEMORY_SIMILARITY = 0.7;

export async function extractMemory(
  userId: string,
): Promise<MemoryExtractionStats> {
  // Gather the latest user-only messages that still need memory extraction.
  const pendingMessages = await getPendingUserMessages(userId);
  if (pendingMessages.length === 0) {
    return EMPTY_STATS;
  }

  // Let the LLM convert free-form conversation into normalized facts.
  const facts = await extractFactsFromMessages(pendingMessages);
  if (facts.length === 0) {
    await markMessagesAsExtracted(pendingMessages.map((msg) => msg.id));
    return {
      ...EMPTY_STATS,
      messagesExtracted: pendingMessages.length,
    };
  }

  // Embed every fact once so we can both search for similar memories
  // and avoid redundant OpenAI calls during insert/update later on.
  const factTexts = facts.map((fact) => fact.text);
  const factEmbeddings = await Embeddding(factTexts);

  // Pull the most relevant existing memories for comparison, using
  // cosine similarity against the freshly embedded facts.
  const existingMemories = await buildExistingMemoryContext({
    userId,
    factEmbeddings,
  });
  const startFactId = existingMemories.length + 1;

  const unifiedExisting = existingMemories.map(({ unifiedId, text }) => ({
    id: unifiedId,
    text,
  }));
  const unifiedNewFacts = facts.map((fact, index) => ({
    id: String(startFactId + index),
    text: fact.text,
    category: fact.category,
    importance: fact.importance,
    confidence: fact.confidence,
  }));

  // Ask the LLM to decide whether each fact is new (ADD) or should
  // revise an existing memory (UPDATE).
  const memoryUpdatePrompt = getUpdateMemoryMessages(
    unifiedExisting,
    unifiedNewFacts,
  );
  const memoryUpdateOutput = await StructureResponse(
    memoryUpdatePrompt,
    MemoryUpdateSchema,
  );

  // Translate LLM output into concrete DB operations and batch any
  // additional embeddings that we still need before touching the DB.
  const decisionPlan = await buildDecisionPlan({
    facts,
    factEmbeddings,
    existingMemories,
    startFactId,
    decisions: memoryUpdateOutput.memory,
  });

  // Apply ADD/UPDATE decisions within a single transaction, then mark
  // all processed messages as extracted.
  const { memoriesAdded, memoriesUpdated } = await applyDecisionPlan({
    userId,
    plan: decisionPlan,
    existingMemories,
    messageIds: pendingMessages.map((msg) => msg.id),
  });

  return {
    factsExtracted: facts.length,
    memoriesAdded,
    memoriesUpdated,
    messagesExtracted: pendingMessages.length,
  };
}

async function extractFactsFromMessages(
  messages: ConversationMessage[],
): Promise<RetrievedFact[]> {
  const conversation = formatMessagesForFactExtraction(messages);
  const prompt = getFactRetrievalMessages(conversation);
  const { facts } = await StructureResponse(prompt, FactRetrievalSchema);
  return facts;
}

function formatMessagesForFactExtraction(
  messages: ConversationMessage[],
): string {
  return messages.map((msg) => `${msg.role}: ${msg.content}`).join("\n\n");
}

async function buildExistingMemoryContext(params: {
  userId: string;
  factEmbeddings: number[][];
}): Promise<ExistingMemory[]> {
  if (params.factEmbeddings.length === 0) {
    return [];
  }

  const similarMemories = await bulkSearchSimilarMemories(
    params.factEmbeddings,
    {
      topK: SIMILAR_MEMORY_TOP_K,
      userId: params.userId,
      minSimilarity: MIN_MEMORY_SIMILARITY,
    },
  );

  const uniqueMemories = new Map<number, { id: number; content: string }>();
  for (const results of similarMemories) {
    for (const { memory: mem } of results) {
      if (!uniqueMemories.has(mem.id)) {
        uniqueMemories.set(mem.id, {
          id: mem.id,
          content: mem.content ?? "",
        });
      }
    }
  }

  return Array.from(uniqueMemories.values()).map((mem, index) => ({
    unifiedId: String(index + 1),
    originalId: mem.id,
    text: mem.content,
  }));
}

async function buildDecisionPlan(params: {
  facts: RetrievedFact[];
  factEmbeddings: number[][];
  existingMemories: ExistingMemory[];
  startFactId: number;
  decisions: MemoryUpdateDecision[];
}): Promise<DecisionPlan> {
  const embeddingByText = new Map<string, number[]>();
  params.facts.forEach((fact, index) => {
    if (!embeddingByText.has(fact.text)) {
      embeddingByText.set(fact.text, params.factEmbeddings[index]);
    }
  });

  const textsToEmbed: string[] = [];
  const pendingEmbeddingTexts = new Set<string>();
  const queueEmbedding = (text: string) => {
    if (!text || embeddingByText.has(text) || pendingEmbeddingTexts.has(text)) {
      return;
    }
    pendingEmbeddingTexts.add(text);
    textsToEmbed.push(text);
  };

  const prepared: PreparedDecision[] = [];
  for (const decision of params.decisions) {
    const decisionId = parseInt(decision.id, 10);
    if (Number.isNaN(decisionId)) {
      continue;
    }

    if (decision.event === "ADD") {
      const factIndex = decisionId - params.startFactId;
      if (factIndex < 0 || factIndex >= params.facts.length) {
        continue;
      }

      const fact = params.facts[factIndex];
      const text = decision.text?.length ? decision.text : fact.text;
      queueEmbedding(text);
      prepared.push({
        kind: "ADD",
        text,
        metadata: {
          category: fact.category,
          importance: fact.importance,
          confidence: fact.confidence,
        },
        embeddingKey: text,
      });
    } else if (decision.event === "UPDATE") {
      const memoryIndex = decisionId - 1;
      if (memoryIndex < 0 || memoryIndex >= params.existingMemories.length) {
        continue;
      }

      const text = decision.text;
      queueEmbedding(text);
      prepared.push({
        kind: "UPDATE",
        memoryIndex,
        text,
        embeddingKey: text,
      });
    }
  }

  const overrideEmbeddings =
    textsToEmbed.length > 0 ? await Embeddding(textsToEmbed) : [];
  textsToEmbed.forEach((text, index) => {
    embeddingByText.set(text, overrideEmbeddings[index]);
  });

  return {
    decisions: prepared,
    embeddingByText,
  };
}

async function applyDecisionPlan(params: {
  userId: string;
  plan: DecisionPlan;
  existingMemories: ExistingMemory[];
  messageIds: number[];
}): Promise<{
  memoriesAdded: number;
  memoriesUpdated: number;
}> {
  let memoriesAdded = 0;
  let memoriesUpdated = 0;

  await db.transaction(async (tx) => {
    for (const decision of params.plan.decisions) {
      const embedding = params.plan.embeddingByText.get(decision.embeddingKey);
      if (!embedding) {
        continue;
      }

      if (decision.kind === "ADD") {
        await tx.insert(memory).values({
          userId: params.userId,
          content: decision.text,
          embedding,
          category: decision.metadata.category,
          importance: decision.metadata.importance,
          confidence: decision.metadata.confidence,
          action: "ADD",
        });
        memoriesAdded++;
        continue;
      }

      const targetMemory = params.existingMemories[decision.memoryIndex];
      if (!targetMemory) {
        continue;
      }

      await tx
        .update(memory)
        .set({
          content: decision.text,
          prevContent: targetMemory.text,
          embedding,
          action: "UPDATE",
        })
        .where(eq(memory.id, targetMemory.originalId));
      memoriesUpdated++;
    }

    await markMessagesAsExtracted(params.messageIds, tx);
  });

  return { memoriesAdded, memoriesUpdated };
}

/**
 * Bulk search for similar memories using vector embeddings
 *
 * @param queries - Array of query embeddings (each should be a 1536-dimensional array)
 * @param options - Search options
 * @param options.topK - Number of top results to return per query (default: 5)
 * @param options.userId - Optional user ID to filter results by user
 * @param options.minSimilarity - Minimum similarity threshold (0-1, default: 0)
 * @param options.category - Optional category filter
 * @returns Array of results, one array per query embedding
 */
export async function bulkSearchSimilarMemories(
  queries: number[][],
  options: {
    userId: string;
    topK?: number;
    minSimilarity?: number;
  },
) {
  const topK = options?.topK ?? 5;
  const minSimilarity = options?.minSimilarity ?? 0;

  // Execute all queries in parallel for better performance
  const results = await Promise.all(
    queries.map((queryEmbedding) =>
      searchSimilarMemories(queryEmbedding, {
        topK,
        userId: options.userId,
        minSimilarity,
      }),
    ),
  );

  return results;
}

/**
 * Search for similar memories using a single query embedding
 * @param queryEmbedding - Query embedding vector (1536 dimensions)
 * @param options - Search options
 * @param options.topK - Number of top results to return (default: 5)
 * @param options.userId - Optional user ID to filter results by user
 * @param options.minSimilarity - Minimum similarity threshold (0-1, default: 0)
 * @returns Array of similar memories with similarity scores
 */
export async function searchSimilarMemories(
  queryEmbedding: number[],
  options: {
    topK: number;
    userId: string;
    minSimilarity?: number;
  },
) {
  const topK = options?.topK ?? 5;
  const minSimilarity = options?.minSimilarity ?? 0;

  // Calculate cosine distance (1 - cosine similarity)
  const similarity = sql<number>`1 - (${cosineDistance(memory.embedding, queryEmbedding)})`;

  return await db
    .select({
      memory: memory,
      similariy: similarity,
    })
    .from(memory)
    .where(
      and(eq(memory.userId, options.userId), gt(similarity, minSimilarity)),
    )
    .orderBy((t) => desc(t.similariy))
    .limit(topK);
}
